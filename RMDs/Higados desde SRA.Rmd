---
title: "Higados desde SRA"
author: "Fernando Lucas Ruiz (fernando.lucas@um.es)"
date: "`r Sys.Date()`"
output:
  html_document:
    df_print: paged
    highlight: kate
    number_sections: true
    theme: spacelab
    toc: true
    toc_float: true
    code_folding: "hide"
  pdf_document:
    toc: true
subtitle: Cirugía digestiva, endocrina y trasplante de órganos abdominales (IMIB)
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F)
```

```{r, message=FALSE}
source("Librerias.R")
```

# Descargar fastq desde SRA

Para ello descargamos la accesion list del proyecto y los metadatos. El proyecto a descargar es: SRP377201.

*"DNA from liver biopsies were extracted and Real-time polymerase chain reaction (qPCR) amplification was performed using 16S universal primers targeting the hypervariable V3-V4 region of the bacterial 16S ribosomal gene with a protocol carefully designed to minimize any risk of contamination between samples or from the experimenters, environment. The quality and quantity of extracted nucleic acids were controlled by gel electrophoresis and absorbance spectroscopy using a NanoDrop 2000 UV spectrophotometer. The qPCR was performed on a ViiA 7 PCR system using Sybr Green technology. The microbial populations based on rDNA present in liver samples were determined using next-generation high-throughput sequenced using the Illumina-MiSeq technology."*

Para conseguir los fastq necesitamos la herramienta sra-toolkit (https://github.com/ncbi/sra-tools/wiki/01.-Downloading-SRA-Toolkit). Una vez descargado, abrimos la terminal y ponemos:

```{bash, eval = FALSE}
tar -xvzf {nombre_del_archivo}.tar.gz

mkdir tmp

cd {nombre_del_archivo}/bin

pwd

export PATH=$PATH:$(paste working directory to {nombre_del_archivo}/bin)

./vpn-config –interactive

CACHE: process-local location: (wherever you want to save the files)
Exit
cd ../../

```

Luego movemos la accesion_list que la llamamos runs.txt al folder donde esta el sra-toolkit y ejecutamos el siguiente codigo para extraer los fastq

```{bash, eval = FALSE}
while read accession; do prefetch $accession fasterq-dump $accession --split-files done < accessions.txt

```

Seguidamente los movemos a una carpeta donde vayamos a trabajar con qiime y los meteremos en una carpeta llamada fastq.

# Qiime2

Lo primero de todo es crear el manifiesto en un archivo tsv. Al ser archivos pareados tiene que tener la siguiente cabecera:
- sample-id
- forward-absolute-filepath
- reverse-absolute-filepath

Una vez tengamos el manifiesto generamos una carpeta nueva llamada qiime y nos metemos. Ejecutamos el siguiente codigo para importarlo a qiime:

```{bash, eval = FALSE}
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path ../fastq/corrected_manifest.tsv \
  --output-path paired-end-demux.qza \
  --input-format PairedEndFastqManifestPhred33V2
```

```{bash, eval = FALSE}
qiime demux summarize \
  --i-data paired-end-demux.qza \ 
  --o-visualization paired-end-demux.qzv 
```

Deblur en un primer paso realiza un filtrado de calidad basado en los quality scores

```{bash, eval = FALSE}
qiime quality-filter q-score \
 --i-demux paired-end-demux.qza \   
 --o-filtered-sequences demux-filtered.qza \
 --o-filter-stats demux-filter-stats.qza
```

```{bash, eval = F}
qiime deblur denoise-16S \
  --i-demultiplexed-seqs demux-filtered.qza \
  --p-trim-length -1 \
  --o-representative-sequences rep-seqs.qza \
  --o-table table.qza \
  --p-sample-stats \
  --o-stats deblur-stats.qza
```

Las estadísticas las pasamos a tabla para poder visualizar los resultados (https://view.qiime2.org/)

```{bash, eval = F}
qiime metadata tabulate \
  --m-input-file demux-filter-stats.qza \
  --o-visualization demux-filter-stats.qzv

qiime deblur visualize-stats \
  --i-deblur-stats deblur-stats.qza \
  --o-visualization deblur-stats.qzv
```


Es este paso podemos generar un árbol filogenético basado en diferentes métricas como la diversidad filogenética de Faith, UniFrac ponderado y no ponderado. El método se basa en un alineamiento múltiple de las secuencias para generar la filogenia en base a la similitud de las mismas.

```{bash, eval = F}
qiime phylogeny align-to-tree-mafft-fasttree \
  --i-sequences rep-seqs.qza \
  --o-alignment aligned-rep-seqs.qza \
  --o-masked-alignment masked-aligned-rep-seqs.qza \
  --o-tree unrooted-tree.qza \
  --o-rooted-tree rooted-tree.qza
```

```{bash, eval = F}
qiime diversity core-metrics-phylogenetic \
  --i-phylogeny rooted-tree.qza \
  --i-table table.qza \
  --p-sampling-depth 1103 \
  --m-metadata-file ../metadata.tsv \
  --output-dir core-metrics-results
```

```{bash, eval = F}
 qiime diversity alpha-group-significance \
 --i-alpha-diversity core-metrics-results/shannon_vector.qza \
 --m-metadata-file ../metadata.tsv \
 --o-visualization core-metrics-results/shannon-group-significance.qzv 
```

```{bash, eval = F}
qiime diversity alpha-rarefaction \
  --i-table table.qza \
  --i-phylogeny rooted-tree.qza \
  --p-max-depth 4000 \
  --m-metadata-file ../metadata.tsv \
  --o-visualization alpha-rarefaction.qzv
```

```{bash, eval = F}
qiime feature-classifier classify-sklearn \
  --i-classifier silva-138-99-nb-classifier.qza \
  --i-reads rep-seqs.qza \
  --o-classification taxonomy.qza

qiime metadata tabulate \
  --m-input-file taxonomy.qza \
  --o-visualization taxonomy.qzv
```

```{bash, eval = F}
qiime taxa barplot \
  --i-table table.qza \
  --i-taxonomy taxonomy.qza \
  --m-metadata-file ../metadata.tsv \
  --o-visualization taxa-bar-plots.qzv
```

Exportar

```{bash, eval = F}
echo "Exportar tabla de conteos a formato biom"
qiime tools extract --input-path table.qza --output-path exports

echo "Convertir fichero biom a tsv"
biom convert -i exports/8f3a3c1c-4c8f-4c71-b778-805b1fa5ccef/data/feature-table.biom -o exports/8f3a3c1c-4c8f-4c71-b778-805b1fa5ccef/data/feature-table.tsv --to-tsv

echo "Convertir taxonomía a tsv"
qiime tools export --input-path taxonomy.qza --output-path exports

echo "Opcional: extraer árbol taxonómico formato newik (nwk)"
qiime tools export --input-path rooted-tree.qza --output-path exports
```

# Importar datos qiime

```{r}

otutable <- read.table("../SRP377201_Liver/qiime/exports/8f3a3c1c-4c8f-4c71-b778-805b1fa5ccef/data/feature-table.tsv", sep = "\t", header = T, skip = 1, comment.char = "")
otutable <- otutable %>% column_to_rownames(var = "X.OTU.ID")

sampleData <- read.table("../SRP377201_Liver/metadata.tsv", sep="\t", header = T)
sampleData <- sampleData %>% column_to_rownames(var = "sampleid")


taxonomy <- read.table("../SRP377201_Liver/qiime/exports/taxonomy.tsv", sep = "\t", header = T)
taxonomy <- taxonomy %>% column_to_rownames(var = "Feature.ID") %>% select(-Confidence)

taxaMatrix <- taxonomy %>% mutate(Taxon = gsub("[a-z]__","", Taxon) ) %>% 
    separate(Taxon, into = c("d","Phylum","Class","Order","Family","Genus","Species"), sep=";" ) 
taxaMatrix[is.na(taxaMatrix)]<-""
taxaMatrix <- taxaMatrix %>%
    dplyr::filter(d == "Bacteria") %>%
    dplyr::select(-d)


nrow(sampleData)

```



# Cargar tse

```{r}
# Ordena las columnas de otutable según el orden de las filas de sampleData
otutable <- otutable[, order(match(colnames(otutable), rownames(sampleData)))]
# coldata rownames match assay colnames
all(rownames(sampleData) == colnames(otutable)) # our dataset
##  [1] TRUE


class(sampleData) # should be data.frame or DataFrame
##  [1] "data.frame"


# rowdata rownames match assay rownames
all(rownames(taxaMatrix) == rownames(otutable))
##  [1] TRUE


class(taxaMatrix) # should be data.frame or DataFrame
##  [1] "data.frame"


# Counts
otutable <- as.matrix(otutable)
class(otutable) # should be a numeric matrix
##  [1] "matrix" "array"
```

## Profundidad de muestreo

```{r}
# Extraer la matriz de abundancias del objeto TSE
abundances <- data.frame(t(otutable))

# Calcular la profundidad mínima
abundances$sample <- rownames(abundances)

abundances_long <- pivot_longer(
  abundances, 
  cols = -sample,  # Especificamos que las columnas de especies deben ser pivotadas
  names_to = "Taxa",           # La nueva columna que contendrá los nombres de las especies
  values_to = "Abundance"        # La nueva columna que contendrá los valores de abundancia
)

abundances_long %>% 
    group_by(sample) %>%
    summarize(n_seqs = sum(Abundance)) %>%
    ggplot(aes(x = n_seqs)) +
    geom_histogram(bins= 100)

abundances_long %>% 
    group_by(sample) %>%
    summarize(n_seqs = sum(Abundance)) %>%
    arrange(n_seqs)

abundances_long %>% 
    group_by(sample) %>%
    summarize(n_seqs = sum(Abundance),
              n_sings = sum(Abundance == 1),
              goods = 100*(1 - n_sings / n_seqs)) %>%
    ggplot(aes(x=n_seqs, y = goods)) +
    geom_point()



```

```{r}
min_n_seqs <- abundances_long %>% 
    dplyr::filter(sample != "SRR19415858") %>%
    group_by(sample) %>%
    summarize(n_seqs = sum(Abundance),
              min = min(n_seqs)) %>%
    pull(min)

quantil1_n_seqs <- abundances_long %>% 
    dplyr::filter(sample != "SRR19415858") %>%
    group_by(sample) %>%
    summarize(n_seqs = sum(Abundance)) %>%
    pull(n_seqs) %>%            
    quantile(probs = 0.25)

abundances <- abundances %>% 
    dplyr::filter(sample != "SRR19415858") %>%
    dplyr::select(-sample)

# Crear curva de rarefacción con los datos originales
rarecurve_data <- rarecurve(abundances, step=100, col="blue", label=T, cex=0.6)
map_dfr(rarecurve_data, bind_rows) %>%
    bind_cols(sample = rownames(abundances),.) %>%
    pivot_longer(-sample) %>%
    drop_na() %>%
    mutate(n_seqs = as.numeric(str_replace(name, "N", ""))) %>%
    select(-name)%>%
    ggplot(aes(x = n_seqs, y = value, group = sample)) +
    geom_vline(xintercept = quantil1_n_seqs, color = "grey", shape = "dashed") +
    geom_line() +
    theme_minimal()+
    labs(x= "number of species", y = "counts", title = "Liver SRA")

# Aplicar rarefacción real a las abundancias
rarefied_abundances <- rrarefy(abundances, sample=quantil1_n_seqs)

# (Opcional) Crear curva de rarefacción con los datos rarefactados
rarecurve_rarefied_data <- rarecurve(rarefied_abundances, step=100, col="blue", label=T, cex=0.6)
map_dfr(rarecurve_rarefied_data, bind_rows) %>%
    bind_cols(sample = rownames(abundances),.) %>%
    pivot_longer(-sample) %>%
    drop_na() %>%
    mutate(n_seqs = as.numeric(str_replace(name, "N", ""))) %>%
    select(-name)%>%
    ggplot(aes(x = n_seqs, y = value, group = sample)) +
    geom_vline(xintercept = quantil1_n_seqs, color = "grey", shape = "dashed") +
    geom_line() +
    theme_minimal()+
    labs(x= "number of species", y = "counts", title = "T1")
```

```{r}
otutable <- t(rarefied_abundances)
sampleData <- sampleData[rownames(sampleData) != "SRR19415858", ]

# Ordena las columnas de otutable según el orden de las filas de sampleData
otutable <- otutable[, order(match(colnames(otutable), rownames(sampleData)))]
# coldata rownames match assay colnames
all(rownames(sampleData) == colnames(otutable)) # our dataset
##  [1] TRUE


class(sampleData) # should be data.frame or DataFrame
##  [1] "data.frame"

# rowdata rownames match assay rownames
common_rows <- intersect(rownames(taxaMatrix), rownames(otutable))

taxaMatrix <- taxaMatrix[common_rows, ]
otutable <- otutable[common_rows, ]
all(rownames(taxaMatrix) == rownames(otutable)) # our dataset
##  [1] TRUE


class(taxaMatrix) # should be data.frame or DataFrame
##  [1] "data.frame"


# Counts
otutable <- as.matrix(otutable)
class(otutable) # should be a numeric matrix
##  [1] "matrix" "array"
```

```{r}
# Create a TreeSE
tse_higado_sra <- TreeSummarizedExperiment(
    assays =  SimpleList(counts = otutable),
    colData = DataFrame(sampleData),
    rowData = DataFrame(taxaMatrix))
```




# Guardar datos

```{r}
save.image("../Rdatas/higados desde SRA.RData")
```
